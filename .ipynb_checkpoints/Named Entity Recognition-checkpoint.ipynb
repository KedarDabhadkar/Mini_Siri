{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"http://174.138.108.232/wp-content/uploads/2017/08/entities.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's that?\n",
    "<hr style=\"height:2px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> <font style=\"FONT-SIZE:15px; COLOR:#000000; LINE-HEIGHT:25px; FONT-FAMILY:Arial,Helvetica,sans-serif\">\n",
    "Named Entity Recognition (NER) is the process of extracting relevant terms (or words) from text- sentences, paragraphs, or articles. Typically in NER, one scans through all the words in a text, tagging each with the most relevant tag from a given dictionary of tags. If a person does this manually, it is very difficult to keep track of the number of times a particular tag has been assigned, to remember the portion of the text where a particular tag appears the most number of times, let alone assess similarity of  texts based on the frequency of these tags. For this reason, NER is done on a large scale using pre-trained algorithms. <br> <br>\n",
    "    &emsp;&emsp; For example, consider the foloowing sentence:<br><br>\n",
    "<mark>The European Union, with U.S. backing,has threatened to refer Iran to the U.N. Security Council, which could impose sanctions if it finds Tehran has violated the Nuclear Non-Proliferation treaty.</mark> <br><br>\n",
    "    \n",
    "When this sentence is run through an NER algorithm, the most likely output is the following: <br> <br>\n",
    "        Organization: <mark>European Union</mark>, <mark>U.N. Security Council</mark><br>\n",
    "        Geopolitical Entity: <mark>U.S.</mark>, <mark>Iran</mark>,<mark>Tehran</mark> <br>\n",
    "        Artifact: <mark>Nuclear Non-Proliferation treaty</mark>\n",
    "<br><br>\n",
    "<a href=\"https://en.wikipedia.org/wiki/Named-entity_recognition\">This</a> wikipedia write-up on NER sums up all the basics of NER as well as some application areas pretty well.\n",
    "\n",
    "<hr style=\"height:4px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where is it used?\n",
    "<hr style=\"height:2px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> <font style=\"FONT-SIZE:15px; COLOR:#000000; LINE-HEIGHT:25px; FONT-FAMILY:Arial,Helvetica,sans-serif\">\n",
    "Some applications of NER as listed in <a href=\"https://towardsdatascience.com/named-entity-recognition-applications-and-use-cases-acdbf57d595e\"> this article</a> are: <br><br>\n",
    "    1. Classifying content for news providers <br>\n",
    "    2. Efficient Search Algorithms<br>\n",
    "    3. Powering Content Recommendations<br>\n",
    "    4. Customer support<br>\n",
    "    5. Research Papers. <br> <br>\n",
    "    \n",
    "   There are many more applications. NER can be used very effectively wherever information has to be selectively extracted from text.\n",
    "   <hr style=\"height:4px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does it work?\n",
    "<hr style=\"height:2px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> <font style=\"FONT-SIZE:15px; COLOR:#000000; LINE-HEIGHT:25px; FONT-FAMILY:Arial,Helvetica,sans-serif\">\n",
    "Basically, the algorithms that power an NER product are classifiers. Classifiers are the algorithms that use statistical or machine learning tools to come up with scores (usually probability) for each tag from a pre-specified pool of tags. A word is assigned a tag with the maximum score (or probability).\n",
    "<hr style=\"height:4px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this work\n",
    "<hr style=\"height:2px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> <font style=\"FONT-SIZE:15px; COLOR:#000000; LINE-HEIGHT:25px; FONT-FAMILY:Arial,Helvetica,sans-serif\">\n",
    "    In this work, a huge dataset of about <b>50,000</b> sentences has been analyzed for making a Named Entity Recognition product. This length is about 10x as much as the length of a mid-size book (<a href=\"https://www.quora.com/How-many-sentences-are-in-a-mid-length-book\">ref</a>). The final aim is to assign tags to each and every word. The dataset has been obtained from <a href=\"https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus\">this</a> Kaggle database. We selectively use the first column, which gives the individual words and the third column, which gives the corresponding tags for our feature engineering experiments.<br><br>\n",
    "    \n",
    "Even though many deep learning models and standard libraries like <a href=\"https://spacy.io/\">Spacy</a> are availabe, we have primarily chosen a  <a href=\"https://en.wikipedia.org/wiki/Logistic_regression\"><b>Logistic Regression</b></a> classifier because our primary intention is to study how a small change in the selection of features affects classification accuracy. All the codes and metric files can be found in <a href=\"https://github.com/dkedar7/Named_Entity_Recognition\">this</a> Github repository. All codes are written in Python using the <a href=\"http://www.numpy.org/\">Numpy</a> module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to consider the following tags:<br>\n",
    "<table style=\"widtd:100%\" align=\"left\">\n",
    "  <tr>\n",
    "    <th>Tag</th>\n",
    "    <th>Description</th> \n",
    "  </tr>\n",
    "    \n",
    "  <tr>\n",
    "    <td>art</td>\n",
    "    <td>Artifact</td> \n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "    <td>eve</td>\n",
    "    <td>Event</td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>geo</td>\n",
    "    <td>Geographical Entity</td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>gpe</td>\n",
    "    <td>Geopolitical Entity</td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>nat</td>\n",
    "    <td>Natural Phenomenon</td>\n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>org</td>\n",
    "    <td>Organization</td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>per</td>\n",
    "    <td>Person</td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>tim</td>\n",
    "    <td>Time indicator</td> \n",
    "  </tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1\n",
    "<hr style=\"height:2px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> <font style=\"FONT-SIZE:15px; COLOR:#000000; LINE-HEIGHT:25px; FONT-FAMILY:Arial,Helvetica,sans-serif\">\n",
    "Model 1 is the simplest model imaginable. For any given datapoint, an individual word corresponding to that datapoint makes up the feature. In other words, the feature matrix is a single column matrix of dimension N x 1, where N is the total number of words in the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature matrix X: <br><br>\n",
    "$\\begin{pmatrix}word \\hspace{0.1cm} 1\\\\ word\\hspace{0.1cm}2\\\\ word\\hspace{0.1cm}3\\\\ ...\\\\ word\\hspace{0.1cm}N\\\\\\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label matrix Y: <br> <br>\n",
    "    $\\begin{pmatrix}tag \\hspace{0.1cm} 1\\\\ tag\\hspace{0.1cm}2\\\\ tag\\hspace{0.1cm}3\\\\ ...\\\\ tag\\hspace{0.1cm}N\\\\\\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:80%\">\n",
    "  <tr>\n",
    "    <th>Tag</th>\n",
    "    <th>Precision</th> \n",
    "    <th>Recall</th>\n",
    "    <th>F1 Score</th>\n",
    "    <th>Number of datapoints under this</th>\n",
    "  </tr>\n",
    "    \n",
    "  <tr>\n",
    "    <td>b-art</td>\n",
    "    <td>0.33333</td> \n",
    "    <td>0.04651</td>\n",
    "    <td>0.08163</td>\n",
    "    <td>43</td>\n",
    "  </tr>\n",
    "    \n",
    "  <tr>\n",
    "    <td>b-eve</td>\n",
    "    <td>0.66667</td> \n",
    "    <td>0.29630</td>\n",
    "    <td>0.41026</td>\n",
    "    <td>27</td>\n",
    "  </tr>\n",
    "    \n",
    "  <tr>\n",
    "    <td>b-geo</td>\n",
    "    <td>0.79778</td> \n",
    "    <td>0.76673</td>\n",
    "    <td>0.78195</td>\n",
    "    <td>3751</td>\n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>b-gpe</td>\n",
    "    <td>0.92446</td> \n",
    "    <td>0.95269</td>\n",
    "    <td>0.93837</td>\n",
    "    <td>1670</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>b-nat</td>\n",
    "    <td>1.00000</td> \n",
    "    <td>0.20000</td>\n",
    "    <td>0.33333</td>\n",
    "    <td>15</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>b-org</td>\n",
    "    <td>0.72855</td> \n",
    "    <td>0.38951</td>\n",
    "    <td>0.50763</td>\n",
    "    <td>2136</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>b-per</td>\n",
    "    <td>0.76718</td> \n",
    "    <td>0.36022</td>\n",
    "    <td>0.49024</td>\n",
    "    <td>1674</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>b-tim</td>\n",
    "    <td>0.88656</td> \n",
    "    <td>0.69536</td>\n",
    "    <td>0.77940</td>\n",
    "    <td>2068</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>i-art</td>\n",
    "    <td>0.00000</td> \n",
    "    <td>0.00000</td>\n",
    "    <td>0.00000</td>\n",
    "    <td>22</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>i-eve</td>\n",
    "    <td>0.00000</td> \n",
    "    <td>0.00000</td>\n",
    "    <td>0.00000</td>\n",
    "    <td>25</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>i-geo</td>\n",
    "    <td>0.66972</td> \n",
    "    <td>0.53441</td>\n",
    "    <td>0.59446</td>\n",
    "    <td>683</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>i-gpe</td>\n",
    "    <td>1.00000</td> \n",
    "    <td>0.18750</td>\n",
    "    <td>0.31579</td>\n",
    "    <td>32</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>i-nat</td>\n",
    "    <td>0.00000</td> \n",
    "    <td>0.00000</td>\n",
    "    <td>0.00000</td>\n",
    "    <td>4</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>i-org</td>\n",
    "    <td>0.63462</td> \n",
    "    <td>0.01887</td>\n",
    "    <td>0.03665</td>\n",
    "    <td>1749</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>i-per</td>\n",
    "    <td>0.76443</td> \n",
    "    <td>0.56616</td>\n",
    "    <td>0.65052</td>\n",
    "    <td>1708</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>i-tim</td>\n",
    "    <td>0.49796</td> \n",
    "    <td>0.19396</td>\n",
    "    <td>0.27918</td>\n",
    "    <td>629</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>o</td>\n",
    "    <td>0.94022</td> \n",
    "    <td>0.99789</td>\n",
    "    <td>0.96820</td>\n",
    "    <td>85194</td>\n",
    "  </tr>\n",
    "    \n",
    "</table>\n",
    "\n",
    "Weighted average F1-score = <b>0.90987</b>\n",
    "\n",
    "<hr style=\"height:4px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2\n",
    "<hr style=\"height:2px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> <font style=\"FONT-SIZE:15px; COLOR:#000000; LINE-HEIGHT:25px; FONT-FAMILY:Arial,Helvetica,sans-serif\">\n",
    "In model 2, model 1 feature matrix has been altered as shown. For any given datapoint, instead of considering only the given word as the feature, one word before the given word and one word after the given word have been considered. In this manner, the feature matrix is modified to account for all the words. The terms 'BOS' and 'EOS' indicating 'Beginning of Sentence' and 'End of Sentence' have been added at the beginning and end of each sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature matrix X: <br><br>\n",
    "$\\begin{pmatrix}\n",
    "BOS \\hspace{0.1cm}  \\hspace{0.3cm}word\\hspace{0.1cm}1\\hspace{0.3cm}word\\hspace{0.1cm}2\\\\ word\\hspace{0.1cm}1\\hspace{0.3cm}word\\hspace{0.1cm}2\\hspace{0.3cm}word\\hspace{0.1cm}3\\\\\n",
    "word\\hspace{0.1cm}2\\hspace{0.3cm}word\\hspace{0.1cm}3\\hspace{0.3cm}word\\hspace{0.1cm}4\\\\\n",
    " ...\\\\\n",
    "word\\hspace{0.1cm}N-1 \\hspace{0.3cm}word\\hspace{0.1cm}N\\hspace{0.3cm}EOS\\\\\\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label matrix Y: <br> <br>\n",
    "    $\\begin{pmatrix}tag \\hspace{0.1cm} 1\\\\ tag\\hspace{0.1cm}2\\\\ tag\\hspace{0.1cm}3\\\\ ...\\\\ tag\\hspace{0.1cm}N\\\\\\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:80%\">\n",
    "  <tr>\n",
    "    <th>Tag</th>\n",
    "    <th>Precision</th> \n",
    "    <th>Recall</th>\n",
    "    <th>F1 Score</th>\n",
    "    <th>Number of datapoints under this</th>\n",
    "  </tr>\n",
    "    \n",
    "  <tr>\n",
    "    <td>b-art</td>\n",
    "    <td>0.30769</td> \n",
    "    <td>0.09302</td>\n",
    "    <td>0.14286</td>\n",
    "    <td>43</td>\n",
    "  </tr>\n",
    "    \n",
    "  <tr>\n",
    "    <td>b-eve</td>\n",
    "    <td>0.0000</td> \n",
    "    <td>0.0000</td>\n",
    "    <td>0.0000</td>\n",
    "    <td>27</td>\n",
    "  </tr>\n",
    "    \n",
    "  <tr>\n",
    "    <td>b-geo</td>\n",
    "    <td>0.79778</td> \n",
    "    <td>0.76673</td>\n",
    "    <td>0.78195</td>\n",
    "    <td>3751</td>\n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>b-gpe</td>\n",
    "    <td>0.92446</td> \n",
    "    <td>0.95269</td>\n",
    "    <td>0.93837</td>\n",
    "    <td>1670</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>b-nat</td>\n",
    "    <td>1.00000</td> \n",
    "    <td>0.20000</td>\n",
    "    <td>0.33333</td>\n",
    "    <td>15</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>b-org</td>\n",
    "    <td>0.72855</td> \n",
    "    <td>0.38951</td>\n",
    "    <td>0.50763</td>\n",
    "    <td>2136</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>b-per</td>\n",
    "    <td>0.76718</td> \n",
    "    <td>0.36022</td>\n",
    "    <td>0.49024</td>\n",
    "    <td>1674</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>b-tim</td>\n",
    "    <td>0.88656</td> \n",
    "    <td>0.69536</td>\n",
    "    <td>0.77940</td>\n",
    "    <td>2068</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>i-art</td>\n",
    "    <td>0.00000</td> \n",
    "    <td>0.00000</td>\n",
    "    <td>0.00000</td>\n",
    "    <td>22</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>i-eve</td>\n",
    "    <td>0.00000</td> \n",
    "    <td>0.00000</td>\n",
    "    <td>0.00000</td>\n",
    "    <td>25</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>i-geo</td>\n",
    "    <td>0.66972</td> \n",
    "    <td>0.53441</td>\n",
    "    <td>0.59446</td>\n",
    "    <td>683</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>i-gpe</td>\n",
    "    <td>1.00000</td> \n",
    "    <td>0.18750</td>\n",
    "    <td>0.31579</td>\n",
    "    <td>32</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>i-nat</td>\n",
    "    <td>0.00000</td> \n",
    "    <td>0.00000</td>\n",
    "    <td>0.00000</td>\n",
    "    <td>4</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>i-org</td>\n",
    "    <td>0.63462</td> \n",
    "    <td>0.01887</td>\n",
    "    <td>0.03665</td>\n",
    "    <td>1749</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>i-per</td>\n",
    "    <td>0.76443</td> \n",
    "    <td>0.56616</td>\n",
    "    <td>0.65052</td>\n",
    "    <td>1708</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>i-tim</td>\n",
    "    <td>0.49796</td> \n",
    "    <td>0.19396</td>\n",
    "    <td>0.27918</td>\n",
    "    <td>629</td>\n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>o</td>\n",
    "    <td>0.94022</td> \n",
    "    <td>0.99789</td>\n",
    "    <td>0.96820</td>\n",
    "    <td>85194</td>\n",
    "  </tr>\n",
    "    \n",
    "</table>\n",
    "\n",
    "Weighted Average F1 score = <b>0.94240</b>\n",
    "\n",
    "<hr style=\"height:4px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
